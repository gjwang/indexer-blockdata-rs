// Cargo.toml ä¾èµ–:
// [dependencies]
// rdkafka = { version = "0.36", features = ["cmake-build"] }
// tokio = { version = "1", features = ["full"] }
// serde = { version = "1.0", features = ["derive"] }
// serde_json = "1.0"
// anyhow = "1.0"
// chrono = "0.4"

use anyhow::Result;
use rdkafka::config::ClientConfig;
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::Message;
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Mutex;

#[derive(Serialize, Deserialize, Debug, Clone)]
struct DemoMessage {
    id: u32,
    content: String,
}

#[derive(Debug, Clone)]
struct LatencyRecord {
    msg_id: u32,
    send_time: Instant,
    receive_time: Option<Instant>,
    producer_latency: Duration,
}

#[derive(Debug)]
struct LatencyStats {
    min: Duration,
    max: Duration,
    avg: Duration,
    p50: Duration,
    p95: Duration,
    p99: Duration,
}

#[tokio::main]
async fn main() -> Result<()> {
    let broker = "localhost:9092";
    let topic = "latency-test-topic";
    let group_id = "latency-consumer-group";

    println!("=== Redpanda å»¶è¿Ÿæµ‹è¯• ===\n");

    // åˆ›å»ºç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…
    let producer = create_producer(broker)?;
    let consumer = create_consumer(broker, group_id)?;
    consumer.subscribe(&[topic])?;

    // è¿è¡Œå»¶è¿Ÿæµ‹è¯•
    println!("ğŸš€ å¼€å§‹å»¶è¿Ÿæµ‹è¯•...\n");
    run_latency_test(&producer, &consumer, topic, 100).await?;

    Ok(())
}

fn create_producer(broker: &str) -> Result<FutureProducer> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", broker)
        .set("message.timeout.ms", "5000")
        .set("linger.ms", "0") // ç«‹å³å‘é€ï¼Œå‡å°‘æ‰¹å¤„ç†å»¶è¿Ÿ
        .set("compression.type", "none") // ç¦ç”¨å‹ç¼©ä»¥å‡å°‘å»¶è¿Ÿ
        .set("acks", "all") // ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
        .create()?;

    println!("âœ… ç”Ÿäº§è€…åˆ›å»ºæˆåŠŸ");
    Ok(producer)
}

fn create_consumer(broker: &str, group_id: &str) -> Result<StreamConsumer> {
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", broker)
        .set("group.id", group_id)
        .set("enable.auto.commit", "true")
        .set("auto.offset.reset", "latest") // åªè¯»å–æ–°æ¶ˆæ¯
        .set("fetch.min.bytes", "1") // ç«‹å³è·å–æ¶ˆæ¯
        .create()?;

    println!("âœ… æ¶ˆè´¹è€…åˆ›å»ºæˆåŠŸ");
    Ok(consumer)
}

async fn run_latency_test(
    producer: &FutureProducer,
    consumer: &StreamConsumer,
    topic: &str,
    message_count: usize,
) -> Result<()> {
    // ä½¿ç”¨ Arc<Mutex> æ¥å…±äº«å»¶è¿Ÿè®°å½•
    let latency_records = Arc::new(Mutex::new(Vec::<LatencyRecord>::new()));
    let records_for_consumer = latency_records.clone();
    let records_for_send = latency_records.clone();

    // å¯åŠ¨æ¶ˆè´¹è€…ä»»åŠ¡ï¼ˆä¸ä½¿ç”¨ spawnï¼Œç›´æ¥åœ¨å½“å‰ä»»åŠ¡ä¸­å¹¶å‘ï¼‰
    println!("ğŸ“¡ å¯åŠ¨æ¶ˆè´¹è€…ç›‘å¬...");

    // ç­‰å¾…æ¶ˆè´¹è€…å‡†å¤‡å¥½
    tokio::time::sleep(Duration::from_secs(2)).await;

    println!("ğŸ“¤ å¼€å§‹å‘é€ {} æ¡æµ‹è¯•æ¶ˆæ¯...\n", message_count);

    // åŒæ—¶å¯åŠ¨å‘é€å’Œæ¥æ”¶ä»»åŠ¡
    let send_task = async { send_messages(producer, topic, records_for_send, message_count).await };

    let receive_task =
        async { consume_messages(consumer, records_for_consumer, message_count).await };

    // å¹¶å‘æ‰§è¡Œå‘é€å’Œæ¥æ”¶
    tokio::join!(send_task, receive_task);

    println!("\nâœ… æµ‹è¯•å®Œæˆï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯...\n");

    // è®¡ç®—å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    let records = latency_records.lock().await;
    print_latency_stats(&records);

    Ok(())
}

async fn send_messages(
    producer: &FutureProducer,
    topic: &str,
    records: Arc<Mutex<Vec<LatencyRecord>>>,
    message_count: usize,
) {
    // å‘é€æ¶ˆæ¯å¹¶è®°å½•å‘é€æ—¶é—´
    for i in 0..message_count {
        let msg = DemoMessage {
            id: i as u32,
            content: format!("å»¶è¿Ÿæµ‹è¯•æ¶ˆæ¯ {}", i),
        };

        let payload = serde_json::to_string(&msg).unwrap();
        let key = format!("key-{}", i);

        let send_start = Instant::now();
        let record_msg = FutureRecord::to(topic).key(&key).payload(&payload);

        match producer.send(record_msg, Duration::from_secs(5)).await {
            Ok(_) => {
                let producer_latency = send_start.elapsed();

                // è®°å½•å‘é€ä¿¡æ¯
                let mut recs = records.lock().await;
                recs.push(LatencyRecord {
                    msg_id: i as u32,
                    send_time: send_start,
                    receive_time: None,
                    producer_latency,
                });

                if (i + 1) % 20 == 0 {
                    println!("  å·²å‘é€ {}/{} æ¡æ¶ˆæ¯", i + 1, message_count);
                }
            }
            Err((e, _)) => {
                eprintln!("  âœ— æ¶ˆæ¯ {} å‘é€å¤±è´¥: {:?}", i, e);
            }
        }

        // æ§åˆ¶å‘é€é€Ÿç‡ï¼Œé¿å…è¿‡å¿«
        tokio::time::sleep(Duration::from_millis(10)).await;
    }

    println!("\nâœ… æ¶ˆæ¯å‘é€å®Œæˆ");
}

async fn consume_messages(
    consumer: &StreamConsumer,
    records: Arc<Mutex<Vec<LatencyRecord>>>,
    expected_count: usize,
) {
    let mut received_count = 0;
    println!("ğŸ“¥ æ¶ˆè´¹è€…å¼€å§‹æ¥æ”¶æ¶ˆæ¯...\n");

    loop {
        match tokio::time::timeout(Duration::from_secs(5), consumer.recv()).await {
            Ok(Ok(msg)) => {
                let receive_time = Instant::now();

                if let Some(payload) = msg.payload() {
                    if let Ok(text) = std::str::from_utf8(payload) {
                        if let Ok(demo_msg) = serde_json::from_str::<DemoMessage>(text) {
                            // æ›´æ–°å¯¹åº”æ¶ˆæ¯çš„æ¥æ”¶æ—¶é—´
                            let mut recs = records.lock().await;
                            if let Some(record) = recs.iter_mut().find(|r| r.msg_id == demo_msg.id)
                            {
                                record.receive_time = Some(receive_time);
                                received_count += 1;

                                if received_count % 20 == 0 {
                                    println!(
                                        "  å·²æ¥æ”¶ {}/{} æ¡æ¶ˆæ¯",
                                        received_count, expected_count
                                    );
                                }

                                if received_count >= expected_count {
                                    break;
                                }
                            }
                        }
                    }
                }
            }
            Ok(Err(e)) => {
                eprintln!("  æ¥æ”¶é”™è¯¯: {:?}", e);
            }
            Err(_) => {
                println!("  æ¥æ”¶è¶…æ—¶ï¼Œå·²æ¥æ”¶ {} æ¡æ¶ˆæ¯", received_count);
                break;
            }
        }
    }
}

fn print_latency_stats(records: &[LatencyRecord]) {
    let mut producer_latencies = Vec::new();
    let mut e2e_latencies = Vec::new();
    let mut received_count = 0;

    for record in records {
        producer_latencies.push(record.producer_latency);

        if let Some(receive_time) = record.receive_time {
            let e2e_latency = receive_time.duration_since(record.send_time);
            e2e_latencies.push(e2e_latency);
            received_count += 1;
        }
    }

    println!("\n{}", "=".repeat(60));
    println!("ğŸ“Š å»¶è¿Ÿæµ‹è¯•ç»“æœ");
    println!("{}", "=".repeat(60));

    println!("\nğŸ“ˆ æµ‹è¯•ç»Ÿè®¡:");
    println!("  æ€»å‘é€æ¶ˆæ¯æ•°: {}", records.len());
    println!("  æˆåŠŸæ¥æ”¶æ•°:   {}", received_count);
    println!(
        "  ä¸¢å¤±ç‡:        {:.2}%",
        (records.len() - received_count) as f64 / records.len() as f64 * 100.0
    );

    if !producer_latencies.is_empty() {
        let producer_stats = calculate_stats(&producer_latencies);
        print_stats("ğŸš€ ç”Ÿäº§è€…å‘é€å»¶è¿Ÿ", &producer_stats);
    }

    if !e2e_latencies.is_empty() {
        let e2e_stats = calculate_stats(&e2e_latencies);
        print_stats("ğŸ”„ ç«¯åˆ°ç«¯å»¶è¿Ÿ (å‘é€â†’æ¥æ”¶)", &e2e_stats);

        // è®¡ç®—æ¶ˆè´¹è€…å»¶è¿Ÿï¼ˆè¿‘ä¼¼ï¼‰
        if !producer_latencies.is_empty() {
            let producer_stats = calculate_stats(&producer_latencies);
            let avg_network_consumer = e2e_stats.avg.saturating_sub(producer_stats.avg);
            println!("\nğŸ“ ç½‘ç»œ+æ¶ˆè´¹è€…å»¶è¿Ÿï¼ˆè¿‘ä¼¼ï¼‰: {:?}", avg_network_consumer);
        }
    }

    println!("\n{}", "=".repeat(60));
}

fn calculate_stats(latencies: &[Duration]) -> LatencyStats {
    let mut sorted = latencies.to_vec();
    sorted.sort();

    let sum: Duration = sorted.iter().sum();
    let len = sorted.len();

    LatencyStats {
        min: *sorted.first().unwrap(),
        max: *sorted.last().unwrap(),
        avg: sum / len as u32,
        p50: sorted[len * 50 / 100],
        p95: sorted[len * 95 / 100],
        p99: sorted[len * 99 / 100],
    }
}

fn print_stats(title: &str, stats: &LatencyStats) {
    println!("\n{}", title);
    println!("{}", "-".repeat(60));
    println!("  æœ€å°å»¶è¿Ÿ (Min):  {:>10.2?}", stats.min);
    println!("  å¹³å‡å»¶è¿Ÿ (Avg):  {:>10.2?}", stats.avg);
    println!("  ä¸­ä½æ•° (P50):    {:>10.2?}", stats.p50);
    println!("  P95 å»¶è¿Ÿ:        {:>10.2?}", stats.p95);
    println!("  P99 å»¶è¿Ÿ:        {:>10.2?}", stats.p99);
    println!("  æœ€å¤§å»¶è¿Ÿ (Max):  {:>10.2?}", stats.max);
}
