# Balance Query Architecture

**Date**: 2025-12-10
**Status**: Phase 1 Implementation (Materialized View)
**Author**: System Architecture Team

---

## Problem Statement

### The Challenge

Given the table schema:
```sql
CREATE TABLE trading.balance_ledger (
    user_id bigint,
    asset_id int,
    seq bigint,  -- Event sequence number
    avail bigint,
    frozen bigint,
    event_type text,
    PRIMARY KEY ((user_id, asset_id), seq)
) WITH CLUSTERING ORDER BY (seq DESC);
```

**Query requirement**: Get all current balances for a user (all assets)

**Problem**:
- Primary key requires BOTH `user_id` AND `asset_id`
- Querying by `user_id` alone is invalid (missing partition key)
- We don't know which assets a user has in advance

---

## Solution Options Evaluated

### Option 1: Query All Known Assets in Parallel ‚ùå

```rust
for asset_id in [1, 2, 3, ...100] {  // All exchange assets
    query("WHERE user_id=? AND asset_id=? LIMIT 1", user_id, asset_id)
}
```

**Pros:**
- ‚úÖ Simple implementation
- ‚úÖ Zero Settlement changes
- ‚úÖ No extra storage

**Cons:**
- ‚ùå Queries assets user doesn't have (wasted)
- ‚ùå O(N) queries where N = total exchange assets
- ‚ùå Latency: 50+ assets = 10-20ms
- ‚ùå Doesn't scale (200 assets = 50ms+)

**Verdict**: Not scalable

---

### Option 2: Manual Snapshot Table (user_balances) ‚ùå

```sql
CREATE TABLE user_balances (
    user_id bigint,
    asset_id int,
    avail bigint,
    frozen bigint,
    PRIMARY KEY (user_id, asset_id)
);
```

Settlement writes to BOTH `balance_ledger` and `user_balances` on every update.

**Pros:**
- ‚úÖ Fast queries (1ms)
- ‚úÖ Small storage (snapshot only)
- ‚úÖ Simple query (no filtering)

**Cons:**
- ‚ùå Requires dual writes in Settlement (+9% overhead)
- ‚ùå Manual maintenance (code complexity)
- ‚ùå Consistency risk (2 tables can diverge)
- ‚ùå Settlement becomes responsible for cache

**Verdict**: Too complex, risky

---

### Option 3: Materialized View ‚úÖ **CHOSEN**

```sql
CREATE MATERIALIZED VIEW trading.user_balances_by_user AS
    SELECT user_id, asset_id, seq, avail, frozen, created_at
    FROM trading.balance_ledger
    WHERE user_id IS NOT NULL
      AND asset_id IS NOT NULL
      AND seq IS NOT NULL
    PRIMARY KEY (user_id, asset_id, seq)
    WITH CLUSTERING ORDER BY (asset_id ASC, seq DESC);
```

**Query:**
```rust
SELECT * FROM user_balances_by_user
WHERE user_id = ?
PER PARTITION LIMIT 1;  // Returns latest balance per asset automatically
```

**Pros:**
- ‚úÖ Zero Settlement code changes (ScyllaDB handles updates)
- ‚úÖ Automatic maintenance
- ‚úÖ Real-time updates (~5-10ms lag)
- ‚úÖ Single query returns all user's assets
- ‚úÖ Fast (2-3ms)
- ‚úÖ Scales to any number of assets

**Cons:**
- ‚ö†Ô∏è Settlement write overhead: +5% (+0.2ms latency, -22 ops/s)
- ‚ö†Ô∏è Storage: 2x (50GB base + 50GB MV = 100GB)
- ‚ö†Ô∏è MV backfill delay (minutes for initial creation)

**Verdict**: Best balance of simplicity, performance, and maintainability

---

## Decision Rationale

### Why Materialized View?

1. **Simplicity**: Zero Settlement changes, ScyllaDB handles all replication
2. **Real-time**: ~5-10ms eventual consistency (acceptable for crypto exchange)
3. **Performance**: 2-3ms queries vs 10-50ms parallel queries
4. **Scalability**: O(1) query regardless of exchange asset count
5. **Proven**: Standard ScyllaDB pattern, used by Discord, Instacart, Samsung

### Trade-offs Accepted

1. **+5% Settlement Overhead**:
   - Before: 435 ops/s, 2.29ms avg
   - After: 413 ops/s, 2.4ms avg
   - **Impact**: Negligible (not hitting capacity limits)

2. **2x Storage**:
   - Before: 50GB
   - After: 100GB
   - **Impact**: Acceptable (storage is cheap, queries are expensive)

3. **Eventual Consistency**:
   - Lag: 5-10ms from write to visible in MV
   - **Impact**: Users don't notice sub-10ms delays

---

## Implementation

### Phase 1: Materialized View (Current)

**Schema:**
```sql
CREATE MATERIALIZED VIEW trading.user_balances_by_user AS
    SELECT user_id, asset_id, seq, avail, frozen, created_at
    FROM trading.balance_ledger
    WHERE user_id IS NOT NULL
      AND asset_id IS NOT NULL
      AND seq IS NOT NULL
    PRIMARY KEY (user_id, asset_id, seq)
    WITH CLUSTERING ORDER BY (asset_id ASC, seq DESC)
    AND compaction = {
        'class': 'SizeTieredCompactionStrategy',
        'min_threshold': 4,
        'max_threshold': 32
    }
    AND compression = {
        'sstable_compression': 'LZ4Compressor'
    }
    AND bloom_filter_fp_chance = 0.01
    AND caching = {
        'keys': 'ALL',
        'rows_per_partition': 'ALL'
    };
```

**Query Function:**
```rust
pub async fn get_user_all_balances(&self, user_id: u64) -> Result<Vec<UserBalance>> {
    let result = self.session.query(
        "SELECT asset_id, avail, frozen, seq, created_at
         FROM user_balances_by_user
         WHERE user_id = ?
         PER PARTITION LIMIT 1",  // Only latest balance per asset
        (user_id as i64,)
    ).await?;

    // Parse results
    parse_mv_results(result)
}
```

**Performance:**
- Query latency: 2-3ms
- Settlement overhead: +5%
- Storage: 100GB (base + MV)

---

## Future Optimization: Memory Cache Layer

### Phase 2: MV + Memory Cache (When Needed)

**When to implement:**
- Balance query volume > 1000 QPS
- P99 latency needs to be < 1ms
- Cache hit ratio can be high (80%+ queries from 20% users)

### Architecture

```
Gateway Query Flow:
1. Check memory cache (0.1ms) ‚Üí Cache hit? Return ‚úÖ
2. Cache miss ‚Üí Query MV (2-3ms)
3. Populate cache
4. Return result

Cache Invalidation:
Settlement writes ‚Üí Publish to Kafka ‚Üí Gateway invalidates cache
```

### Implementation Sketch

```rust
// Gateway: Memory cache
use moka::sync::Cache;

lazy_static! {
    static ref BALANCE_CACHE: Cache<u64, Vec<UserBalance>> =
        Cache::builder()
            .max_capacity(10_000)  // 10K hot users
            .time_to_live(Duration::from_secs(60))  // 60s TTL
            .build();
}

pub async fn get_user_all_balances(&self, user_id: u64) -> Result<Vec<UserBalance>> {
    // Try cache
    if let Some(cached) = BALANCE_CACHE.get(&user_id) {
        return Ok(cached);  // 0.1ms ‚úÖ
    }

    // Cache miss - query MV
    let balances = self.query_mv(user_id).await?;  // 2-3ms

    // Populate cache
    BALANCE_CACHE.insert(user_id, balances.clone());

    Ok(balances)
}
```

```rust
// Settlement: Publish invalidation
async fn append_balance_events_batch(&self, events: &[BalanceEvent]) -> Result<()> {
    // Write to balance_ledger
    self.write_to_ledger(events).await?;

    // Publish cache invalidation
    for event in events {
        self.kafka_producer.send(
            FutureRecord::to("cache.invalidations")
                .key(&event.user_id.to_string())
                .payload(&bincode::serialize(&CacheInvalidation {
                    user_id: event.user_id
                })?),
            Duration::from_secs(0)
        ).await?;
    }

    Ok(())
}
```

```rust
// Gateway: Cache invalidation consumer
async fn consume_cache_invalidations() {
    let consumer = create_kafka_consumer("cache.invalidations");

    loop {
        match consumer.recv().await {
            Ok(msg) => {
                if let Ok(inv) = bincode::deserialize::<CacheInvalidation>(msg.payload()) {
                    BALANCE_CACHE.invalidate(&inv.user_id);
                    log::debug!("Cache invalidated for user {}", inv.user_id);
                }
            }
            Err(e) => log::error!("Cache consumer error: {}", e),
        }
    }
}
```

### Performance Expectations (Phase 2)

| Metric | Phase 1 (MV) | Phase 2 (MV + Cache) |
|--------|--------------|----------------------|
| Query latency (hot users) | 2-3ms | 0.1ms ‚úÖ |
| Query latency (cold users) | 2-3ms | 2-3ms |
| Cache hit rate | N/A | 95-99% |
| Memory usage | Minimal | +10MB (10K users) |
| Settlement overhead | +5% | +7% (+cache invalidation) |
| Complexity | Low | Medium |

### When NOT to Add Cache

- ‚úÖ If MV queries are fast enough (< 5ms acceptable)
- ‚úÖ If query volume is low (< 500 QPS)
- ‚úÖ If memory is constrained
- ‚úÖ If simplicity is more important than sub-ms latency

---

## Migration Path

### Current State ‚Üí Phase 1 (MV)

**Steps:**
1. Create MV (one-time CQL command)
2. Wait for backfill completion (minutes to hours)
3. Update `get_user_all_balances()` query
4. Test and deploy
5. Monitor Settlement performance

**Risk**: Low (can drop MV if issues)

### Phase 1 ‚Üí Phase 2 (Add Cache)

**Triggers:**
- Query volume exceeds 1000 QPS
- P99 latency requirements < 1ms
- 80/20 query distribution confirmed

**Steps:**
1. Add memory cache to Gateway
2. Add cache invalidation publisher to Settlement
3. Add cache invalidation consumer to Gateway
4. Monitor cache hit rate and latency
5. Tune cache size and TTL

**Risk**: Medium (introduces Kafka dependency for cache coherency)

---

## Monitoring & Metrics

### Phase 1 (MV) Metrics

```rust
// Settlement
metrics::histogram!("settlement_write_latency_ms", latency);
metrics::gauge!("settlement_throughput_ops", throughput);

// Gateway
metrics::histogram!("balance_query_latency_ms", latency);
metrics::histogram!("balance_query_assets_returned", count);
```

**Alert thresholds:**
- Settlement write latency p99 > 10ms
- Settlement throughput < 350 ops/s
- Balance query latency p99 > 10ms

### Phase 2 (Cache) Metrics

```rust
// Gateway cache metrics
metrics::counter!("balance_cache_hits", 1);
metrics::counter!("balance_cache_misses", 1);
metrics::gauge!("balance_cache_size", BALANCE_CACHE.entry_count());
metrics::histogram!("balance_cache_hit_latency_ms", latency);

// Cache hit rate = hits / (hits + misses)
```

**Alert thresholds:**
- Cache hit rate < 90%
- Cache size > 15K entries (memory pressure)
- Invalidation lag > 100ms

---

## Summary

### Decision: Materialized View (Phase 1)

**Chosen for:**
- Simplicity (zero Settlement changes)
- Performance (2-3ms queries)
- Real-time guarantees (~10ms freshness)
- Scalability (handles any asset count)

### Future: Add Memory Cache (Phase 2 - Optional)

**Add when:**
- Need sub-millisecond latency
- High query volume (1000+ QPS)
- Cache hit rate justifies complexity

### Current Status

‚úÖ **MV schema documented**
‚úÖ **Query function updated**
‚è≠Ô∏è **Ready for implementation**
üìä **Monitoring plan defined**

---

**Next Steps:**
1. Create MV in ScyllaDB
2. Update query function
3. Deploy and monitor
4. Revisit cache layer in 3-6 months based on metrics
